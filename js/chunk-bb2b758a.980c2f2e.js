(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-bb2b758a"],{"4fe8":function(e,t,a){"use strict";a.r(t);var o=function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("div",{staticClass:"project"},[o("h1",[e._v("Cinder Audio")]),e._m(0),o("div",{staticClass:"content side-by-side"},[o("b-img",{staticClass:"media audio-layers",attrs:{right:"",src:a("5458")}}),e._m(1),e._m(2)],1),e._m(3),e._m(4),o("div",{staticClass:"content"},[o("h2",[e._v("Applications")]),e._m(5),o("h4",[e._v("Face Controlled Synth")]),e._m(6),o("b-embed",{staticClass:"media",attrs:{type:"iframe",aspect:"16by9",allowfullscreen:"",src:"https://player.vimeo.com/video/351084708"}}),o("h4",[e._v("Falling Gears")]),e._m(7),o("b-embed",{staticClass:"media",attrs:{type:"iframe",aspect:"16by9",allowfullscreen:"",src:"https://player.vimeo.com/video/108706095"}}),o("h4",[e._v("Symphonologie")]),e._m(8),o("b-embed",{staticClass:"media",attrs:{type:"iframe",aspect:"16by9",allowfullscreen:"",src:"https://player.vimeo.com/video/191749869"}})],1)])},i=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"topInfo"},[a("p",[e._v(" 2012 - 2014"),a("br"),e._v(" Source Code: part of the "),a("a",{attrs:{href:"https://github.com/cinder/cinder"}},[e._v("Cinder C++ Framework")])])])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" While working at The Barbarian Group, I took on the redesign of the Cinder audio API ("),a("code",[e._v("ci::audio")]),e._v("), with the goals of creating something both powerful and flexible enough to be directly combined with Cinder's graphics capabilities. We went with a modular design in the likes of Pure Data and Web Audio, maintaining the spirit of providing C++ tools to build the engine you want. ")])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" Below is a discussion of some of the nice features in this audio library, while you can refer to the "),a("a",{attrs:{href:"https://libcinder.org/docs/guides/audio/index.html"}},[e._v("cinder audio guide")]),e._v(" and the "),a("a",{attrs:{href:"https://github.com/cinder/Cinder/tree/master/samples/_audio"}},[e._v("shipped samples")]),e._v(" for in depth usage details. ")])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"content"},[a("h2",[e._v("Library Features")]),a("h4",[e._v("Native Device Management")]),a("p",[e._v(" We wanted to have tight control over the audio processing at an OS level, so there is a hardware abstraction on each platform. This allows us to minimize dependencies and make tweaks when we need them even at production time. We support a number of platforms (Windows, OS X, iOS, Linux, Android), so I'd say this was the largest aspect of the project concerning development time. However once built, it's a great thing to have, especially when real-time low-latency is your target. ")]),a("h4",[e._v("Built-in Nodes")]),a("p",[e._v(" Like any nice modular audio API, there are some nice things you can use out of the box to build custom audio engines or effects. For sample playback, there is the "),a("code",[e._v("BufferPlayerNode")]),e._v(" (in-memory) and "),a("code",[e._v("FilePlayerNode")]),e._v(" (streaming)\\ (see "),a("a",{attrs:{href:"https://libcinder.org/docs/guides/audio/index.html#read_audio"}},[e._v("notes here")]),e._v("). For waveform generation, there are both low level nodes (sinewave, triangle, phase, etc) as well as the band-limited "),a("code",[e._v("GenOscNode")]),e._v(" that has presets for the common waveform types. Nodes for filtering and delay are also in there, as well as general math operations or just using a C++11 lambda to do some audio processing. "),a("a",{attrs:{href:"https://libcinder.org/docs/guides/audio/index.html#other_nodes"}},[e._v("Details")]),e._v(". ")]),a("p",[e._v(" Nodes in "),a("code",[e._v("ci::audio")]),e._v(" can be multi-channel for ease of use (default is they match their inputs, but this can be overridden). You use ChannelRouterNode to both separate channels from multi-channel nodes and to remap mono nodes, for example when designing a spatialized multi-channel audio engine. ")]),a("h4",[e._v("Digital Signal Processing")]),a("p",[e._v(" At the core, there's an audio library for doing typical audio math, like vector math operations, windowing, sample-rate conversion, and FFT (Fast Fourier Transform). All the other components build on this efficiency-orientated layer, although the "),a("code",[e._v("cinder::audio::dsp")]),e._v(" namespace is also meant to be used in end projects when needed. ")]),a("h4",[e._v("Sample Accurate Scheduling")]),a("p",[e._v(" One very nice feature in "),a("code",[e._v("ci::audio")]),e._v(" is the ability to schedule events with sub-sample accuracy. This allows you to synchronize things running on other threads (commonly visuals, but can also be networking events, etc). You do this by specifying a time in the future, usually within the next processing block. Audio params are controlled in a similar fashion although with a bit more control, using the "),a("code",[e._v("Param")]),e._v(" mechanism. Most of the built-in nodes expose their parameters using these where it makes sense. Similar to the Web Audio API, you can also use other "),a("code",[e._v("ci::audio::Node")]),e._v("s as inputs to "),a("code",[e._v("ci::audio::Param")]),e._v(". ")])])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"content"},[a("h2",[e._v("Cinder Blocks (Add-ons)")]),a("p",[e._v(" Because of the modular structure and native C++ API, it's easy to extend "),a("code",[e._v("ci::audio")]),e._v("'s built-in functionality by adding custom Nodes for synthesis, effects, custom processing, or adding other platform-specific backends. Here are some that are public on github. ")]),a("h4",[e._v("Blocks extending "),a("code",[e._v("ci::audio::Node")]),e._v("s")]),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/richardeakin/Cinder-Stk"}},[e._v("Cinder-Stk")]),e._v(" - adds support for the "),a("a",{attrs:{href:"https://ccrma.stanford.edu/software/stk/index.html"}},[e._v("Synthesis Toolkit")]),e._v(", also wrapping many useful tools as Nodes for things like reverb, chorus, synth instruments, etc. Personally, I've used it in many projects for the "),a("a",{attrs:{href:"https://ccrma.stanford.edu/software/stk/classstk_1_1FreeVerb.html"}},[e._v("FreeVerb")]),e._v(" implementation. ")]),a("li",[a("a",{attrs:{href:"https://github.com/richardeakin/Cinder-HISSConvolver"}},[e._v("Cinder-HISSConvolver")]),e._v(" - adds a Node for convolution using the HISSTools Impulse Response Toolbox. Commonly used for convolution reverb, or just create interesting sound designs on real-time audio signals. ")]),a("li",[a("a",{attrs:{href:"https://github.com/notlion/Cinder-PureDataNode"}},[e._v("Cinder-PureDataNode")]),e._v(" - wraps Pure Data within a Node, allowing you to write embedded pd patches, while also allowing you to use cinder to handle difficult cross-platform things like hardware i/o, file i/o, sample-rate conversion, and other low-level DSP operations. Also mentioned at PdCon16 ("),a("a",{attrs:{href:"http://www.nyu-waverlylabs.org/pdcon16/wp-content/uploads/2017/02/Proceedings_of_the_5th_International_Pure_Data_Convention.pdf"}},[e._v("proceedings")]),e._v(', "libpd: Past, Present, and Future of Embedding Pure Data). ')])]),a("h4",[e._v("Blocks using "),a("code",[e._v("ci::audio::Node")]),e._v("s")]),a("ul",[a("li",[a("a",{attrs:{href:"Cinder-SoundPlayer"}},[e._v("Cinder-SoundPlayer")]),e._v(" - from "),a("a",{attrs:{href:"https://redpaperheart.com/"}},[e._v("eRed Paper Heart")]),e._v(", provides higher-level audio file playback common in user interfaces. dev branch has some nice improvements (from me) for playback via a 'Buffer pool'. This is crucial in things like sound effects where you want them to be able to overlap. ")]),a("li",[a("a",{attrs:{href:"https://github.com/Potion/Cinder-poSoundManager"}},[e._v("Cinder-poSoundManager")]),e._v(" - from Potion Design, similar audio file playback tool, with some more features like pan, loop, etc. ")])]),a("h4",[e._v("Blocks adding extra Hardware Backends")]),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/cinder/Cinder-PortAudio"}},[e._v("Cinder-PortAudio")]),e._v(" - allows you to use PortAudio as an additional audio hardware backend, selectable at runtime, notably used for adding ASIO / Dante support. More info on "),a("a",{attrs:{href:"https://discourse.libcinder.org/t/cinder-portaudio-portaudio-as-an-alternative-audio-backend/1346"}},[e._v("this forum post")]),e._v(". ")])])])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" Here are some projects that I've worked on using"),a("code",[e._v("ci::audio")]),e._v(" that reach a bit beyond the run-of-the-mill sample file playback scenario. ")])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" A collaboration with "),a("a",{attrs:{href:"https://rarevolume.com/"}},[e._v("Rare Volume")]),e._v(" using face movement and gestures to drive a combination of subtractive synthesis and studio audio compositions. Face joint positions and velocities were mapped to track volumes and parameters on a custom subtractive synthesis arrangement. The choice of audio tracks was driven based on extracted 'mood', which was mapped to the level of various tracks. ")])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" This is a sample that "),a("a",{attrs:{href:"https://github.com/cinder/Cinder/tree/master/samples/FallingGears/src"}},[e._v("ships with cinder")]),e._v(", demonstrating physics driven audio synthesis. Gears fall when you drag your mouse and collisions between gears and walls or 'islands' trigger sound generators ("),a("code",[e._v("ci::audio::GenNode")]),e._v("s) that are spatially arranged to make musical chords. ")])},function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("p",[e._v(" Another "),a("a",{attrs:{href:"https://rarevolume.com/work/symphonologie/"}},[e._v("Rare Volume project")]),e._v(", held at the Louvre in Paris. This time, visuals were driving audio. Five microphones were used to isolate different sections of the symphony, which were analyzed as amplitude envelopes and magnitude frequency spectrums. During the project, I added support for MSW low-latency mode, a key step in obtaining a tight and highly reactive music visualizer on the Windows platform. ")])}],s={},r=s,n=(a("6668"),a("2877")),d=Object(n["a"])(r,o,i,!1,null,"604b0e71",null);t["default"]=d.exports},5458:function(e,t,a){e.exports=a.p+"img/audio_layers.83691fb4.png"},6668:function(e,t,a){"use strict";a("aea4")},aea4:function(e,t,a){}}]);
//# sourceMappingURL=chunk-bb2b758a.980c2f2e.js.map